{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9379cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu, corpus_bleu\n",
    "from nsd_access import NSDAccess\n",
    "import os, sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6cddc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'all_subjects'\n",
    "epoch = 71\n",
    "# model = 'subject_2_baseline2'\n",
    "# epoch = 80\n",
    "# model = 'subject_2_both_layer_norm'\n",
    "# epoch = 25\n",
    "\n",
    "model_path = f'/home/hpcgies1/Masters-Thesis/AttemptFour/Log/{model}/eval_out/output_captions_{epoch}.npy'\n",
    "home_dir = f'/home/hpcgies1/Masters-Thesis/AttemptFour/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56114ba",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3cf1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsd_loader = NSDAccess('/home/hpcgies1/rds/hpc-work/NIC/NSD/')\n",
    "nsd_loader.stim_descriptions = pd.read_csv(nsd_loader.stimuli_description_file, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24a18e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    return np.squeeze(np.load(open(fname, 'rb')), axis=-1)\n",
    "\n",
    "def load_tokenizer(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        tok =tokenizer_from_json(f.read())\n",
    "    return tok\n",
    "\n",
    "def remove_pad_end(cap: str):\n",
    "    cap = cap.split(\" \")\n",
    "    cap = [i for i in cap if i != '<pad>' and i != '<end>']\n",
    "    return \" \".join(cap)\n",
    "\n",
    "def get_target_caption(key):\n",
    "    \"\"\" Return target caption for a given key in [1,73000] \"\"\"\n",
    "    with HiddenPrints():\n",
    "        target = nsd_loader.read_image_coco_info([int(key)-1]) # returns list(dict)\n",
    "        target = target[0]['caption'] # get first target caption\n",
    "    return target\n",
    "\n",
    "def get_target_captions(keys: list):\n",
    "    \"\"\" Return target caption for a given key in [1,73000] \"\"\"\n",
    "    keys = [int(i)-1 for i in keys]\n",
    "    output_targets = []\n",
    "    with HiddenPrints():\n",
    "        targets = nsd_loader.read_image_coco_info(keys) # returns list(list(dict))\n",
    "    for _, t in enumerate(targets):\n",
    "        ts = []\n",
    "        for i in range(5):\n",
    "            target = t[i]['caption'] # get target captions\n",
    "            ts.append(target)\n",
    "        output_targets.append(ts)\n",
    "    return output_targets\n",
    "\n",
    "def clean_targets(targets: list):\n",
    "    \"\"\" given list of list of targets: return cleaned strings \"\"\"\n",
    "    new = []\n",
    "    for i in range(len(targets)):\n",
    "        ts = []\n",
    "        for k in range(5):\n",
    "            t = targets[i][k]\n",
    "            t = t.replace(\".\",\" \").replace(\",\", \" \").strip().split(\" \")\n",
    "            t = [n.lower() for n in t if n != '']\n",
    "            t = \" \".join(t)\n",
    "            ts.append(t)\n",
    "        new.append(ts)\n",
    "    return new\n",
    "\n",
    "class HiddenPrints:\n",
    "    \"\"\" Use with with HiddenPrints() to temporarily surpress print output \"\"\"\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa2987",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c11071d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4120, 15)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = load_tokenizer(f'/home/hpcgies1/Masters-Thesis/AttemptFour/Log/{model}/eval_out/tokenizer.json')\n",
    "test_keys = pd.read_csv(f'{home_dir}/TrainData/subj02_conditions2.csv')\n",
    "test_keys = test_keys['nsd_key'].loc[test_keys['is_test'] == 1].values\n",
    "output = load_data(model_path)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7cae7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4120\n",
      "515\n"
     ]
    }
   ],
   "source": [
    "captions = tokenizer.sequences_to_texts(output)\n",
    "print(len(captions))\n",
    "targets = get_target_captions(test_keys)\n",
    "targets = clean_targets(targets)\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8dc41131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5601214574898785\n",
      "0.374840023975205\n",
      "0.2513694386607573\n",
      "0.17357007227610402\n",
      "0.17357007227610402\n"
     ]
    }
   ],
   "source": [
    "def compute_bleu(captions: list, targets: list):\n",
    "    captions = [remove_pad_end(c) for c in captions]\n",
    "    \n",
    "    weights = [\n",
    "        (1, 0, 0, 0),\n",
    "        (0, 1, 0, 0),\n",
    "        (0, 0, 1, 0),\n",
    "        (0, 0, 0, 1),\n",
    "        (1./1., 0, 0, 0),\n",
    "        (1./2., 1./2., 0, 0),\n",
    "        (1./3., 1./3., 1./3., 0),\n",
    "        (1./4., 1./4., 1./4., 1./4.)\n",
    "    ]\n",
    "    \n",
    "    hypothesis = []\n",
    "    references = []\n",
    "    for i in range(1):\n",
    "        caps = captions[i*515:i*515+515]\n",
    "        for i in range(len(caps)):\n",
    "            ref = [i.split(\" \") for i in targets[i]]\n",
    "            hyp = caps[i].split(\" \")\n",
    "            hypothesis.append(hyp)\n",
    "            references.append(ref)\n",
    "\n",
    "    chencherry = SmoothingFunction()\n",
    "    for w in weights[4:]:\n",
    "        b_score = corpus_bleu(references, hypothesis, weights=w, smoothing_function=chencherry.method0)\n",
    "        print(b_score)\n",
    "    return b_score\n",
    "\n",
    "bleu = compute_bleu(captions, targets)\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c280b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26a3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f883141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e52a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
